# JikiME-ADK LLM Router Configuration
# Usage: jikime router switch <provider>
#
# API keys are read from environment variables automatically:
#   OPENAI_API_KEY, GEMINI_API_KEY, GLM_API_KEY
# Set them in ~/.zshrc or ~/.bashrc

router:
  port: 8787
  host: "127.0.0.1"
  provider: openai  # active provider for proxy mode

providers:
  openai:
    model: gpt-5.1
    base_url: https://api.openai.com/v1

  gemini:
    model: gemini-2.5-flash
    base_url: https://generativelanguage.googleapis.com

  glm:
    model: glm-4.7
    base_url: https://api.z.ai/api/paas/v4
    anthropic_url: https://api.z.ai/api/anthropic  # direct mode (no proxy needed)
    region: international  # international or china

  ollama:
    model: llama3.1
    base_url: http://localhost:11434

# Scenario-based routing (optional)
# scenarios:
#   default: openai/gpt-5.1
#   background: ollama/llama3.1
#   think: openai/o1
#   long_context: gemini/gemini-2.5-flash
#   long_context_threshold: 60000
